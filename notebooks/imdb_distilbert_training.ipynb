{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer-based models like DistilBERT have revolutionized natural language processing. In this project, we explore DistilBERT's effectiveness in sentiment analysis on IMDb movie reviews. Our aim is to train a model that accurately predicts whether a review is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch, transformers, datasets\n",
    "    print(\"✅ All libraries imported!\")\n",
    "    print(\"torch\", torch.__version__)\n",
    "    print(\"transformers\", transformers.__version__)\n",
    "    print(\"datasets\", datasets.__version__)\n",
    "except ModuleNotFoundError as e:\n",
    "    print(\"❌\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Point to the mounted CSV\n",
    "data_path = \"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\"\n",
    "\n",
    "imdb_ds = load_dataset(\"csv\", data_files={\"train\": data_path}, split=\"train\")\n",
    "print(imdb_ds)\n",
    "print(\"\\nSample ➜\", imdb_ds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split 90 % train / 10 % validation\n",
    "split_ds = imdb_ds.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds = split_ds[\"train\"]\n",
    "val_ds   = split_ds[\"test\"]\n",
    "\n",
    "print(\"Train rows:\", len(train_ds))\n",
    "print(\"Val rows  :\", len(val_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "label2id = {\"negative\": 0, \"positive\": 1}\n",
    "\n",
    "def preprocess_batch(batch):\n",
    "    batch[\"label\"] = [label2id[s] for s in batch[\"sentiment\"]]\n",
    "    enc = tokenizer(batch[\"review\"], padding=\"max_length\",\n",
    "                    truncation=True, max_length=256)\n",
    "    batch.update(enc); return batch\n",
    "\n",
    "tokenized_train = train_ds.map(preprocess_batch, batched=True,\n",
    "                               remove_columns=[\"review\", \"sentiment\"])\n",
    "tokenized_val   =  val_ds.map(preprocess_batch, batched=True,\n",
    "                               remove_columns=[\"review\", \"sentiment\"])\n",
    "tokenized_train.set_format(\"torch\",\n",
    "                           columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "tokenized_val.set_format(\"torch\",\n",
    "                         columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "# 1️⃣  load pretrained model (num_labels=2 -> binary sentiment)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2,\n",
    ")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return accuracy_metric.compute(predictions=preds, references=labels)\n",
    "\n",
    "# 3️⃣  training hyper-parameters\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"checkpoints\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    seed=42,\n",
    "    report_to=[\"none\"]\n",
    ")\n",
    "\n",
    "# 4️⃣  Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 5️⃣  start fine-tuning (≈2 h on Kaggle P100)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣  Evaluate on the validation split\n",
    "eval_metrics = trainer.evaluate()\n",
    "print(\"Validation metrics ➜\", eval_metrics)\n",
    "\n",
    "# 2️⃣  Confirm which checkpoint was judged 'best'\n",
    "print(\"Best checkpoint path ➜\", trainer.state.best_model_checkpoint)\n",
    "\n",
    "# 3️⃣  Save that best model for inference\n",
    "trainer.save_model(\"distilbert-imdb\")      # writes folder in /kaggle/working\n",
    "print(\"✅ Model saved to distilbert-imdb/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r distilbert-imdb.zip distilbert-imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -R /kaggle/working/distilbert-imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣  create the project directory\n",
    "!mkdir -p /kaggle/working/imdb-sentiment\n",
    "\n",
    "# 2️⃣  copy the model folder into that project\n",
    "!cp -r /kaggle/working/distilbert-imdb /kaggle/working/imdb-sentiment/\n",
    "\n",
    "# 3️⃣  show the new layout\n",
    "!ls -R /kaggle/working/imdb-sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 1️⃣  load the same tokenizer you used for training\n",
    "tok = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# 2️⃣  save it next to the model files\n",
    "tok.save_pretrained(\"/kaggle/working/imdb-sentiment/distilbert-imdb\")\n",
    "\n",
    "# 3️⃣  show the final contents\n",
    "import os, glob, textwrap\n",
    "files = glob.glob(\"/kaggle/working/imdb-sentiment/distilbert-imdb/*\")\n",
    "print(textwrap.fill('\\n'.join(os.path.basename(f) for f in files), width=80))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p /kaggle/working/imdb-sentiment/api\n",
    "\n",
    "cat > /kaggle/working/imdb-sentiment/api/main.py <<'PY'\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# --- load model & tokenizer -----------------------------------------------\n",
    "MODEL_PATH = \"imdb-sentiment/distilbert-imdb\"   # relative to working dir\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "model.eval().to(\"cpu\")                          # GPU not needed for demo\n",
    "\n",
    "label_map = {0: \"negative\", 1: \"positive\"}\n",
    "\n",
    "# --- FastAPI app ----------------------------------------------------------\n",
    "app = FastAPI(title=\"IMDb Sentiment API\")\n",
    "\n",
    "class Item(BaseModel):\n",
    "    text: str\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(item: Item):\n",
    "    inputs = tokenizer(\n",
    "        item.text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        pred   = int(torch.argmax(logits, dim=-1))\n",
    "        score  = float(torch.softmax(logits, dim=-1)[0, pred])\n",
    "    return {\"label\": label_map[pred], \"confidence\": round(score, 4)}\n",
    "PY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /kaggle/working/imdb-sentiment/api/main.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q fastapi uvicorn[standard] \"requests>=2.31\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi.testclient import TestClient\n",
    "import importlib.util, sys, pathlib\n",
    "\n",
    "# Dynamically import the api module we just wrote\n",
    "spec = importlib.util.spec_from_file_location(\n",
    "    \"imdb_api\", pathlib.Path(\"/kaggle/working/imdb-sentiment/api/main.py\")\n",
    ")\n",
    "api_module = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"imdb_api\"] = api_module\n",
    "spec.loader.exec_module(api_module)\n",
    "\n",
    "client = TestClient(api_module.app)\n",
    "\n",
    "resp = client.post(\"/predict\", json={\"text\": \"A surprisingly fun movie!\"})\n",
    "print(\"Status code:\", resp.status_code)\n",
    "print(\"Response JSON:\", resp.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaggle/working/imdb-sentiment\n",
    "\n",
    "# ── requirements.txt ──\n",
    "cat > requirements.txt <<'REQ'\n",
    "fastapi\n",
    "uvicorn[standard]\n",
    "torch>=2.2\n",
    "transformers>=4.41\n",
    "REQ\n",
    "\n",
    "# ── Dockerfile ──\n",
    "cat > Dockerfile <<'DOCK'\n",
    "# ---- base image ----\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# ---- install deps ----\n",
    "COPY requirements.txt /tmp/\n",
    "RUN pip install --no-cache-dir -r /tmp/requirements.txt\n",
    "\n",
    "# ---- copy app & model ----\n",
    "COPY api/ /app/api/\n",
    "COPY distilbert-imdb/ /app/distilbert-imdb/\n",
    "\n",
    "# ---- expose + run ----\n",
    "WORKDIR /app\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "CMD [\"uvicorn\", \"api.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"80\"]\n",
    "DOCK\n",
    "\n",
    "ls -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r imdb-sentiment.zip imdb-sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np, torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "MODEL_PATH = \"/kaggle/working/imdb-sentiment/distilbert-imdb\"\n",
    "\n",
    "# 1. Load test split (25 000 reviews)\n",
    "test_ds = load_dataset(\"imdb\", split=\"test\")\n",
    "\n",
    "# 2. Load tokenizer & model\n",
    "tok   = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH).to(\"cuda\").eval()\n",
    "\n",
    "# 3. Batched inference\n",
    "batch_size = 64\n",
    "correct = 0\n",
    "for i in range(0, len(test_ds), batch_size):\n",
    "    texts  = test_ds[i : i + batch_size][\"text\"]\n",
    "    labels = test_ds[i : i + batch_size][\"label\"]\n",
    "    enc    = tok(texts, padding=True, truncation=True, max_length=256, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        preds = torch.argmax(model(**enc).logits, dim=-1).cpu().numpy()\n",
    "    correct += int(np.sum(preds == labels))\n",
    "\n",
    "test_acc = correct / len(test_ds)\n",
    "print(f\"✅ Test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, torch, transformers, datasets\n",
    "print(\"python:\", sys.version)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"datasets:\", datasets.__version__)\n",
    "print(\"transformers location:\", transformers.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U evaluate --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Target Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(3, 6))\n",
    "sns.countplot(x='sentiment', data=df, palette='Set2')\n",
    "plt.title('Distribution of Sentiment Labels', fontsize=16)\n",
    "plt.xlabel('Sentiment', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df['sentiment'].value_counts()\n",
    "colors = ['#66c2a5', '#fc8d62']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%', startangle=140, colors=colors)\n",
    "plt.title('Distribution of Sentiment Labels')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (DistilBERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df['review'].tolist()\n",
    "labels = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews, val_reviews, train_labels, val_labels = train_test_split(reviews, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert/distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for tokenizing the reviews\n",
    "\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenize_function(train_reviews)\n",
    "val_encodings = tokenize_function(val_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Hugging Face Dataset format\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "                                    'input_ids': train_encodings['input_ids'],\n",
    "                                    'attention_mask': train_encodings['attention_mask'],\n",
    "                                    'labels': train_labels\n",
    "                                    })\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "                                    'input_ids': val_encodings['input_ids'],\n",
    "                                    'attention_mask': val_encodings['attention_mask'],\n",
    "                                    'labels': val_labels\n",
    "                                    })\n",
    "\n",
    "dataset = DatasetDict({\n",
    "                        'train': train_dataset,\n",
    "                        'validation': val_dataset\n",
    "                        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert/distilbert-base-uncased-finetuned-sst-2-english', num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load F1 metric\n",
    "f1_metric = load_metric(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluation metric\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = (preds == labels).mean()\n",
    "    \n",
    "    # Calculate F1-score (weighted)\n",
    "    f1 = f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"f1\": f1[\"f1\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',                     # Output directory for model checkpoints\n",
    "    num_train_epochs=5,                         # Number of training epochs\n",
    "    per_device_train_batch_size=16,             # Batch size per device (GPU/CPU)\n",
    "    per_device_eval_batch_size=16,              # Evaluation batch size\n",
    "    warmup_steps=100,                           # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,                          # Weight decay for regularization\n",
    "    logging_dir='./logs',                       # Directory for logging\n",
    "    logging_steps=10,                           # Interval for logging updates\n",
    "    evaluation_strategy='epoch',                # Evaluate at each epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,                # Load the best model based on eval_loss\n",
    "    metric_for_best_model=\"eval_loss\",          # Use validation loss to determine the best model\n",
    "    greater_is_better=False,                    # Lower validation loss is better\n",
    "    report_to=\"none\",                           # Disable reporting to Hugging Face Hub\n",
    "    push_to_hub=False,                          # Do not push to Hugging Face Hub\n",
    "    fp16=True,                                  # Enable mixed precision\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['validation'],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)\n",
    "print()\n",
    "print(f\"Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-Score: {eval_results['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our experiment with DistilBERT on IMDb reviews, we achieved a peak accuracy score of 0.9371 and an F1-score of 0.9371, demonstrating the effectiveness of transformer-based models for sentiment analysis. By fine-tuning DistilBERT with optimized hyperparameters, including validation loss as the metric for model selection, we balanced performance and generalization efficiently.\n",
    "\n",
    "The model’s consistent improvements in accuracy and F1-score, despite slight increases in validation loss, highlight the importance of monitoring multiple metrics. With its efficiency and adaptability, DistilBERT proves to be a robust solution for text classification tasks, offering a strong foundation for further exploration and refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 134715,
     "sourceId": 320111,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
